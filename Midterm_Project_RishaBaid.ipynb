{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project Title\n",
        "Earnings-Call Language & Short‑Term Market Reaction:\n",
        "\n",
        "\n",
        "An Exploratory Analysis of Management Tone & Post-Announcement Stock Returns"
      ],
      "metadata": {
        "id": "FAMFZC0TXdbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Objective\n",
        "\n",
        "\n",
        "To examine how the tone and linguistic style of corporate earnings calls influence short-term stock market reactions"
      ],
      "metadata": {
        "id": "zr13xu_kn2uB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goals\n",
        "\n",
        "- Quantify management sentiment using NLP features such as polarity, emotional intensity, and sentence complexity.\n",
        "\n",
        "- Analyze the relationship between sentiment measures and post-announcement returns (1-day, 3-day, 5-day, and CAR5).\n",
        "\n",
        "- Compare sentiment–return dynamics across sectors to identify variation in market sensitivity.\n",
        "\n",
        "- Explore which linguistic features (positive/negative word counts, uncertainty, sentence length) most strongly correlate with abnormal returns."
      ],
      "metadata": {
        "id": "rjUEb-d6pOPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Size\n",
        "\n",
        "\n",
        "This study focuses on the top 2 companies (by market cap) for 5 main sectors i.e. Technology, Communication Services, Consumer Discretionary,  Health Care, Financials"
      ],
      "metadata": {
        "id": "9hJNDsBLrMPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Sources\n",
        "\n",
        "- Constituents List: The list of S&P 500 companies was obtained from\n",
        "https://datahub.io/core/s-and-p-500-companies/r/constituents.csv.\n",
        "- Transcripts: `defeatbeta_api` → `Ticker(...).earning_call_transcripts()`; `content_full` concatenated per call.  \n",
        "- Prices & Benchmark: `yfinance` → daily prices for tickers + SPY; compute 1/3/5‑day returns and CAR5.  \n",
        "- Firm Metadata: `yfinance.info` → sector/industry and `market_cap_billion`.\n"
      ],
      "metadata": {
        "id": "N29qC7fwpqxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "xI0BvW_7ruFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "ayf_5vGJy3yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding the top 2 companies (by market cap) from 5 main sectors through the S&P500 market data.**"
      ],
      "metadata": {
        "id": "fr4v_5B0sIRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp500_url = \"https://datahub.io/core/s-and-p-500-companies/r/constituents.csv\" #getting top marketcap companies from s&p500 csv file\n",
        "\n",
        "response = requests.get(sp500_url)\n",
        "print(response)                  # <Response [200]>\n",
        "print(response.text[:500])       # preview first 500 chars\n",
        "\n",
        "#read the CSV text into a DataFrame\n",
        "from io import StringIO\n",
        "sp500 = pd.read_csv(StringIO(response.text))\n",
        "sp500.head()\n"
      ],
      "metadata": {
        "id": "ut_E3AO736qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the columns and prep tickers\n",
        "sp500 = sp500.rename(columns={\"Symbol\": \"ticker\", \"GICS Sector\": \"gics_sector\"})\n",
        "sp500[\"ticker\"] = sp500[\"ticker\"].astype(str).str.replace(\".\", \"-\", regex=False)  # BRK.B -> BRK-B for Yahoo\n",
        "\n",
        "#Keep only these main 5 sectors\n",
        "target_map = {\n",
        "    \"Information Technology\": \"Technology\",\n",
        "    \"Communication Services\": \"Communication Services\",\n",
        "    \"Consumer Discretionary\": \"Consumer Discretionary\",\n",
        "    \"Health Care\": \"Health Care\",\n",
        "    \"Financials\": \"Financials\"\n",
        "}\n",
        "\n",
        "sp500 = sp500[sp500[\"gics_sector\"].isin(target_map.keys())].copy()\n",
        "sp500[\"chosen_sector\"] = sp500[\"gics_sector\"].map(target_map)\n",
        "\n",
        "sp500[[\"ticker\",\"gics_sector\",\"chosen_sector\"]].head()\n"
      ],
      "metadata": {
        "id": "Sx9eLF-P4EZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pull market caps from Yahoo finance\n",
        "rows = []\n",
        "for i in range(len(sp500)):\n",
        "    t = sp500.iloc[i][\"ticker\"]\n",
        "    s = sp500.iloc[i][\"chosen_sector\"]\n",
        "    try:\n",
        "        info = yf.Ticker(t).info\n",
        "        mc = info.get(\"marketCap\", None)\n",
        "    except Exception:\n",
        "        mc = None\n",
        "    print(t, mc)\n",
        "    rows.append({\"ticker\": t, \"chosen_sector\": s, \"market_cap\": mc})\n",
        "    time.sleep(0.05)\n",
        "\n",
        "#Create DataFrame, remove missing market caps, and clean formatting\n",
        "mktcaps = pd.DataFrame(rows).dropna(subset=[\"market_cap\"]).copy()\n",
        "mktcaps[\"market_cap\"] = mktcaps[\"market_cap\"].astype(\"int64\")\n",
        "\n",
        "#Sort by sector and descending market cap for easy comparison\n",
        "mktcaps = mktcaps.sort_values([\"chosen_sector\",\"market_cap\"], ascending=[True, False])\n",
        "mktcaps.head()\n"
      ],
      "metadata": {
        "id": "mYVCiDDZ4ezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick the top 2 companies per sector\n",
        "top2 = []\n",
        "\n",
        "#Filter companies in the current sector and take the top 2 largest by market cap\n",
        "for sector in mktcaps[\"chosen_sector\"].unique():\n",
        "    top2.append(mktcaps[mktcaps[\"chosen_sector\"] == sector].head(2))\n",
        "    #Combine all sector subsets into one DataFrame\n",
        "top2 = pd.concat(top2, ignore_index=True)\n",
        "\n",
        "top2_display = top2[[\"chosen_sector\",\"ticker\",\"market_cap\"]].copy()\n",
        "top2_display[\"market_cap_bn\"] = (top2_display[\"market_cap\"]/1e9).round(1)\n",
        "top2_display\n"
      ],
      "metadata": {
        "id": "7bfwAHum4thy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dictionary to reuse later\n",
        "sector_tickers = {}\n",
        "for sec in top2[\"chosen_sector\"].unique():\n",
        "    sector_tickers[sec] = top2[top2[\"chosen_sector\"] == sec][\"ticker\"].tolist()\n",
        "sector_tickers\n"
      ],
      "metadata": {
        "id": "rYtWAvGW4zkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flatten to a DataFrame and verify sectors from Yahoo Finance\n",
        "rows = []\n",
        "for sector, tickers in sector_tickers.items():\n",
        "    for t in tickers:\n",
        "        info = yf.Ticker(t).info  #metadata call\n",
        "        market_cap = info.get(\"marketCap\", None)\n",
        "        rows.append({\n",
        "            \"chosen_sector\": sector,\n",
        "            \"ticker\": t,\n",
        "            \"yf_sector\": info.get(\"sector\"),\n",
        "            \"yf_industry\": info.get(\"industry\"),\n",
        "            \"shortName\": info.get(\"shortName\"),\n",
        "            \"market_cap\": market_cap,\n",
        "            \"market_cap_billion\": round(market_cap / 1e9, 2) if market_cap else None\n",
        "        })\n",
        "\n",
        "universe = pd.DataFrame(rows)\n",
        "universe\n"
      ],
      "metadata": {
        "id": "dcKMfpztJp5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting earnings-call transcripts from the DefeatBeta API [https://github.com/defeat-beta/defeatbeta-api/].**"
      ],
      "metadata": {
        "id": "VwZ6NtH5t0Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installations for Earnings Call API (defeatbeta-api)\n",
        "!python -m venv venv\n",
        "!source venv/bin/activate\n",
        "!pip install -U pip\n",
        "!pip install defeatbeta-api"
      ],
      "metadata": {
        "id": "FzIPrVTUE2hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the Ticker class from Earnings Call transcript API\n",
        "from defeatbeta_api.data.ticker import Ticker\n"
      ],
      "metadata": {
        "id": "JugVfvvWE7zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flatten dictionary into a simple list of tickers\n",
        "tickers = [t for tickers_list in sector_tickers.values() for t in tickers_list]\n",
        "tickers\n"
      ],
      "metadata": {
        "id": "qdwPa_yPqniU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pull the transcripts list (includes transcripts + transcripts_id)\n",
        "all_meta = []\n",
        "for tk in tickers:\n",
        "    tr = Ticker(tk).earning_call_transcripts()\n",
        "    meta = tr.get_transcripts_list()\n",
        "    meta[\"symbol\"] = tk\n",
        "    all_meta.append(meta)\n",
        "\n",
        "meta_df = pd.concat(all_meta, ignore_index=True)\n",
        "\n",
        "#Clean the date format\n",
        "meta_df[\"report_date\"] = pd.to_datetime(meta_df[\"report_date\"], errors=\"coerce\").dt.date\n",
        "\n",
        "#Keep the last 10 years of data(by fiscal_year)\n",
        "current_year = pd.Timestamp.today().year\n",
        "keep_years = set(range(current_year - 9, current_year + 1))  #inclusive window of 10 years\n",
        "meta_10y = meta_df[meta_df[\"fiscal_year\"].astype(int).isin(keep_years)].copy()\n",
        "\n",
        "#Drop any duplicates per symbol/year/quarter (keeping the latest entry if duplicates exist)\n",
        "meta_10y = (\n",
        "    meta_10y.sort_values([\"symbol\",\"fiscal_year\",\"fiscal_quarter\"], ascending=[True, False, False])\n",
        "            .drop_duplicates(subset=[\"symbol\",\"fiscal_year\",\"fiscal_quarter\"], keep=\"first\")\n",
        "            .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "#Quick preview\n",
        "print(meta_10y.head(10))\n",
        "print(meta_10y.shape)\n"
      ],
      "metadata": {
        "id": "Mb36hCEeHJP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetching full transcript text for each row in meta_10y\n",
        "#Building a new list of rows that includes `content_full`\n",
        "rows = []\n",
        "\n",
        "#Group once per symbol to avoid re-instantiating too much\n",
        "for sym, sub in meta_10y.groupby(\"symbol\"):\n",
        "    print(\"Fetching:\", sym)\n",
        "    tr = Ticker(sym).earning_call_transcripts()\n",
        "    #Loop through each fiscal year–quarter pair for that symbol\n",
        "    for _, r in sub.iterrows():\n",
        "        y = int(r['fiscal_year'])\n",
        "        q = int(r['fiscal_quarter'])\n",
        "        try:\n",
        "            tdf = tr.get_transcript(y, q)\n",
        "            #If transcript exists, merge all text into one string\n",
        "            if tdf is not None and not tdf.empty:\n",
        "                content_full = \" \".join(tdf['content'].astype(str).tolist())\n",
        "            else:\n",
        "                content_full = \"\"\n",
        "        except Exception as e:\n",
        "            print(f\"  {sym} {y}Q{q} error: {e}\")\n",
        "            content_full = \"\"\n",
        "        #Append one record per transcript\n",
        "        rows.append({\n",
        "            \"symbol\": sym,\n",
        "            \"fiscal_year\": y,\n",
        "            \"fiscal_quarter\": q,\n",
        "            \"report_date\": r['report_date'],\n",
        "            \"transcripts\": r.get('transcripts', None),\n",
        "            \"transcripts_id\": r.get('transcripts_id', None),\n",
        "            \"content_full\": content_full\n",
        "        })\n",
        "\n",
        "#Combine all transcripts into a single DataFrame\n",
        "df_calls = pd.DataFrame(rows)\n",
        "print(\"Calls with text:\", df_calls.shape)\n",
        "df_calls.head()\n"
      ],
      "metadata": {
        "id": "8bGBrETzZFDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vader for Sentimental Analysis\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "SEDxM0EG3KLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Word lists for simple counts (aside from vader)\n",
        "positive_words = ['grow','strong','opportunity','success','increase','improve','excellent','benefit','positive','gain','accelerat','robust']\n",
        "negative_words = ['risk','challenge','concern','declin','difficult','uncertain','loss','threat','negative','headwind','weak']\n",
        "uncertainty_words = ['risk','uncertain','may','could','might','possibly','assume','estimate']\n",
        "\n",
        "def compute_key_features(text: str):\n",
        "    #Defaults for missing\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return {\n",
        "            'vader_mean': np.nan,\n",
        "            'vader_pos_share': np.nan,\n",
        "            'vader_neg_share': np.nan,\n",
        "            'vader_neu_share': np.nan,\n",
        "            'positive_word_count': 0,\n",
        "            'negative_word_count': 0,\n",
        "            'uncertainty_word_count': 0,\n",
        "            'pos_neg_ratio': np.nan,\n",
        "            'avg_sentence_length': np.nan,\n",
        "        }\n",
        "\n",
        "    #Sentence-level VADER (avoids saturation)\n",
        "    sentences = re.split(r'[.!?]+\\s+', text.strip())\n",
        "    sentences = [s for s in sentences if len(s.split()) >= 3]\n",
        "    if sentences:\n",
        "        scores = np.array([sia.polarity_scores(s)['compound'] for s in sentences], dtype=float)\n",
        "        vader_mean = float(scores.mean())\n",
        "        vader_pos_share = float((scores > 0.05).mean())\n",
        "        vader_neg_share = float((scores < -0.05).mean())\n",
        "        vader_neu_share = float(((scores >= -0.05) & (scores <= 0.05)).mean())\n",
        "        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences)\n",
        "    else:\n",
        "        sc = sia.polarity_scores(text)['compound']\n",
        "        vader_mean, vader_pos_share, vader_neg_share, vader_neu_share = sc, np.nan, np.nan, np.nan\n",
        "        avg_sentence_length = np.nan\n",
        "\n",
        "    #Simple word-list counts\n",
        "    t = text.lower()\n",
        "    pos_count = sum(t.count(w) for w in positive_words)\n",
        "    neg_count = sum(t.count(w) for w in negative_words)\n",
        "    unc_count = sum(t.count(w) for w in uncertainty_words)\n",
        "\n",
        "    return {\n",
        "        'vader_mean': vader_mean,\n",
        "        'vader_pos_share': vader_pos_share,\n",
        "        'vader_neg_share': vader_neg_share,\n",
        "        'vader_neu_share': vader_neu_share,\n",
        "        'positive_word_count': int(pos_count),\n",
        "        'negative_word_count': int(neg_count),\n",
        "        'uncertainty_word_count': int(unc_count),\n",
        "        'pos_neg_ratio': (pos_count / max(neg_count, 1)),\n",
        "        'avg_sentence_length': avg_sentence_length,\n",
        "    }\n",
        "\n",
        "#Applying to the transcripts table\n",
        "features = df_calls['content_full'].apply(compute_key_features).apply(pd.Series)\n",
        "df_final = pd.concat([df_calls.reset_index(drop=True), features.reset_index(drop=True)], axis=1)\n",
        "\n",
        "#Quick preview\n",
        "df_final[['symbol','vader_mean','vader_pos_share','vader_neg_share','vader_neu_share','positive_word_count','negative_word_count','uncertainty_word_count','pos_neg_ratio','avg_sentence_length']].head()\n"
      ],
      "metadata": {
        "id": "jzgcbd9C_cAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#Computing features on `content_full` and attaching to the same DataFrame\n",
        "feat_df = df_calls['content_full'].apply(compute_key_features).apply(pd.Series)\n",
        "\n",
        "df_final = pd.concat([df_calls, feat_df], axis=1)\n",
        "\n",
        "def trim_disclaimer(text, n_chars=1500):\n",
        "    #Dropping the first N characters (forward-looking disclaimers) to reduce bias\n",
        "    return text[n_chars:] if isinstance(text, str) and len(text) > n_chars else text\n",
        "\n",
        "#Quick preview\n",
        "print(df_final.shape)\n",
        "df_final.head(3)\n"
      ],
      "metadata": {
        "id": "chtvkLo2Zsmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Combining all the data to make one big DataFrame\n",
        "#Events table: one row per (symbol, report_date)\n",
        "events = (\n",
        "    df_final[['symbol', 'report_date']]\n",
        "    .dropna()\n",
        "    .assign(report_date=lambda d: pd.to_datetime(d['report_date']).dt.date)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "#Yahoo uses '-' instead of '.' (e.g., BRK.B -> BRK-B)\n",
        "def to_yahoo(s):\n",
        "    return str(s).replace('.', '-')\n",
        "\n",
        "#Building ticker list + adding SPY for benchmark\n",
        "tickers = sorted({to_yahoo(s) for s in events['symbol']})\n",
        "if 'SPY' not in tickers:\n",
        "    tickers.append('SPY')\n",
        "\n",
        "#Small buffer around the earliest/latest event date\n",
        "dmin = pd.to_datetime(events['report_date']).min() - pd.Timedelta(days=20)\n",
        "dmax = pd.to_datetime(events['report_date']).max() + pd.Timedelta(days=20)\n",
        "\n",
        "#Downloading all prices in one shot\n",
        "#Auto_adjust=True gives adjusted \"Close\" (splits/dividends handled) so can just use Close\n",
        "data = yf.download(tickers, start=dmin, end=dmax, progress=False, auto_adjust=True)[['Close','Volume']]\n",
        "\n",
        "#Getting a single Series for (field, symbol)\n",
        "def get_series(frame, field, symbol):\n",
        "    #Yfinance returns MultiIndex columns when multiple tickers are requested\n",
        "    if isinstance(frame.columns, pd.MultiIndex):\n",
        "        if (field, symbol) in frame.columns:\n",
        "            return frame[(field, symbol)].dropna()\n",
        "        #Some versions shape as (symbol, field)\n",
        "        if (symbol, field) in frame.columns:\n",
        "            return frame[(symbol, field)].dropna()\n",
        "        return pd.Series(dtype=float)\n",
        "    else:\n",
        "        #Single ticker case\n",
        "        return frame[field].dropna() if field in frame.columns else pd.Series(dtype=float)\n",
        "\n",
        "#Computing simple event-window metrics for one (symbol, date)\n",
        "def event_metrics(symbol, event_date, benchmark='SPY'):\n",
        "    s = to_yahoo(symbol)\n",
        "    p = get_series(data, 'Close', s)      #Price series\n",
        "    v = get_series(data, 'Volume', s)     #Volume series\n",
        "    b = get_series(data, 'Close', benchmark)  #Benchmark price\n",
        "\n",
        "    #Basic metrics\n",
        "    if p.empty or b.empty:\n",
        "        return pd.Series({\n",
        "            'day0': pd.NaT,\n",
        "            'price_return_1day': np.nan,\n",
        "            'price_return_3day': np.nan,\n",
        "            'price_return_5day': np.nan,\n",
        "            'bench_return_5day': np.nan,\n",
        "            'CAR5': np.nan,\n",
        "            'volume_change': np.nan\n",
        "        })\n",
        "\n",
        "    #Alignning event date to the next available trading day (if earnings date is weekend/holiday)\n",
        "    t0 = pd.Timestamp(event_date)\n",
        "    #Position of first index >= t0\n",
        "    i0 = p.index.searchsorted(t0)\n",
        "    if i0 >= len(p):\n",
        "        #Event past last price\n",
        "        return pd.Series({\n",
        "            'day0': pd.NaT,\n",
        "            'price_return_1day': np.nan,\n",
        "            'price_return_3day': np.nan,\n",
        "            'price_return_5day': np.nan,\n",
        "            'bench_return_5day': np.nan,\n",
        "            'CAR5': np.nan,\n",
        "            'volume_change': np.nan\n",
        "        })\n",
        "\n",
        "    #Clamping window indices\n",
        "    i_m1 = max(0, i0 - 1)             #Previous trading day\n",
        "    i_p3 = min(len(p) - 1, i0 + 3)    #+3 trading days\n",
        "    i_p5 = min(len(p) - 1, i0 + 5)    #+5 trading days\n",
        "\n",
        "    #Prices\n",
        "    p_m1, p0, p_p3, p_p5 = p.iloc[i_m1], p.iloc[i0], p.iloc[i_p3], p.iloc[i_p5]\n",
        "\n",
        "    #Alignning benchmark to stock trading calendar\n",
        "    b_aligned = b.reindex(p.index).ffill()\n",
        "    b_m1, b_p5 = b_aligned.iloc[i_m1], b_aligned.iloc[i_p5]\n",
        "\n",
        "    #Simple window returns (relative to t-1)\n",
        "    r1  = (p0   / p_m1) - 1.0\n",
        "    r3  = (p_p3 / p_m1) - 1.0\n",
        "    r5  = (p_p5 / p_m1) - 1.0\n",
        "    rb5 = (b_p5 / b_m1) - 1.0\n",
        "    car5 = r5 - rb5\n",
        "\n",
        "    #Same-day volume pop vs t-1\n",
        "    vol_chg = np.nan\n",
        "    if not v.empty:\n",
        "        v_m1 = v.iloc[i_m1]\n",
        "        v0   = v.iloc[i0]\n",
        "        vol_chg = (v0 / v_m1) - 1.0 if (pd.notna(v_m1) and v_m1 != 0) else np.nan\n",
        "\n",
        "    return pd.Series({\n",
        "        'day0': p.index[i0].date(),\n",
        "        'price_return_1day': float(r1),\n",
        "        'price_return_3day': float(r3),\n",
        "        'price_return_5day': float(r5),\n",
        "        'bench_return_5day': float(rb5),\n",
        "        'CAR5': float(car5),\n",
        "        'volume_change': float(vol_chg) if pd.notna(vol_chg) else np.nan\n",
        "    })\n",
        "\n",
        "#Computing metrics for every event\n",
        "metrics = events.apply(lambda r: event_metrics(r['symbol'], r['report_date']), axis=1)\n",
        "events_with_returns = pd.concat([events, metrics], axis=1)\n",
        "\n",
        "#Merging back to the sentiment table\n",
        "df_big = df_final.merge(events_with_returns, on=['symbol','report_date'], how='left')\n",
        "\n",
        "#Adding the sector/name/marketcap from the 'universe' table built earlier\n",
        "if 'universe' in globals():\n",
        "    keep_cols = ['symbol','shortName','chosen_sector','yf_industry','market_cap_billion']\n",
        "    df_big = df_big.merge(\n",
        "        universe.rename(columns={'ticker':'symbol'})[keep_cols],\n",
        "        on='symbol', how='left'\n",
        "    )\n",
        "    #Reorder a few columns to the front\n",
        "    front = ['symbol','shortName','chosen_sector','yf_industry','market_cap_billion','report_date']\n",
        "    rest = [c for c in df_big.columns if c not in front]\n",
        "    df_big = df_big[front + rest]\n",
        "\n",
        "print(df_big.shape)\n",
        "df_big.head()\n"
      ],
      "metadata": {
        "id": "ypGbLMkTxdDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Variables\n",
        "- **Identifiers:** `symbol`, `shortName`, `chosen_sector`, `yf_industry`, `market_cap_billion`, `report_date`, `fiscal_year`, `fiscal_quarter`  \n",
        "- **Text/Sentiment:** `vader_mean`, `vader_pos_share`, `vader_neg_share`, `vader_neu_share`  \n",
        "- **Polarity & Style:** `positive_word_count`, `negative_word_count`, `uncertainty_word_count`, `pos_neg_ratio`, `avg_sentence_length`  \n",
        "- **Market Reaction:** `price_return_1day`, `price_return_3day`, `price_return_5day`, `bench_return_5day`, `CAR5`, `volume_change`\n"
      ],
      "metadata": {
        "id": "eT-TbvwlvySv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_big.columns #all the columns in the big DataFrame"
      ],
      "metadata": {
        "id": "IMUwKim19YrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis"
      ],
      "metadata": {
        "id": "v8fAxqCxvTdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "DJ4Jd2No3wlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Research Questions\n",
        "1) Does more positive management tone lead to stronger short‑term returns?\n",
        "   - Compare VADER sentiment (mean/pos/neg shares) to 1‑day, 3‑day, 5‑day returns and CAR5.\n",
        "\n",
        "2) Are some sectors more sentiment‑sensitive than others?  \n",
        "   - Slice by sector and compare CAR5 across Low / Medium / High sentiment groups.\n",
        "\n",
        "3) Which linguistic features (polarity, emotional intensity, sentence complexity) matter most?\n",
        "   - Relate positive/negative/uncertainty word counts, pos/neg ratio, emotion intensity, and average sentence length to CAR5 and trading volume change.\n"
      ],
      "metadata": {
        "id": "xe0I8yeYxRre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Do companies that use more “positive” management language in earnings calls experience higher\n",
        "#short-term returns post-announcement (1-day, 3-day, 5-day)?"
      ],
      "metadata": {
        "id": "W7MMl2EQ4kbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_big[['price_return_1day', 'price_return_3day', 'price_return_5day']].describe()\n",
        "\n",
        "#Interpretation\n",
        "#Returns range from –26% to +33% over five days — a wide spread showing that while most firms cluster near zero, a few experience sharp post-call moves.\n",
        "#The standard deviation roughly doubles from day 1 to day 5, meaning volatility compounds as reactions unfold.\n",
        "#Median returns are low (≈ 0.17%, 0.67%, 0.85%), reinforcing that the “average” firm sees only modest drift after the announcement.\n"
      ],
      "metadata": {
        "id": "e1Jg3Vel6VBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_big[['vader_mean', 'price_return_1day', 'price_return_3day', 'price_return_5day', 'CAR5']].corr()\n",
        "\n",
        "#Interpretation\n",
        "#Correlation analysis reveals a weak but positive relationship between management sentiment and\n",
        "#short-term stock performance, consistent across 1-, 3-, and 5-day windows. The strong intercorrelations\n",
        "#among return measures (ρ > 0.9 between 3-day, 5-day, and CAR5) indicate that cumulative returns capture\n",
        "#nearly all short-term reaction dynamics, validating the use of CAR5 as the representative performance metric.\n",
        "\n"
      ],
      "metadata": {
        "id": "YNsY88eU561k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorize sentiment into groups\n",
        "bins = [0.08, 0.22, 0.28, 0.38]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df_big['sentiment_level'] = pd.cut(df_big['vader_mean'], bins=bins, labels=labels, include_lowest=True)\n"
      ],
      "metadata": {
        "id": "2meTgvNFy2fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary Statistics by Sentiment Group\n",
        "df_big.groupby('sentiment_level')[['CAR5', 'volume_change']].describe()\n",
        "\n",
        "#Intepretation\n",
        "#Trading activity is strongest after negative/neutral tone calls — possibly because uncertainty or\n",
        "#bad news triggers more repositioning and information trading. As sentiment becomes more positive, volume\n",
        "#spikes are smaller and less volatile, indicating that upbeat tone generates less surprise or urgency among investors.\n",
        "\n"
      ],
      "metadata": {
        "id": "F2lCu4cUORKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing the average CAR5 between Low vs. High sentiment categories\n",
        "\n",
        "low_mean = df_big[df_big['sentiment_level'] == 'Low']['CAR5'].mean()\n",
        "high_mean = df_big[df_big['sentiment_level'] == 'High']['CAR5'].mean()\n",
        "diff = high_mean - low_mean\n",
        "print(f\"Difference in mean CAR5 (High - Low): {diff:.4f}\")\n",
        "\n",
        "#Intepretation\n",
        "#Firms classified as having high management sentiment exhibited, on average, a 0.54\n",
        "#percentage point higher five-day cumulative abnormal return (CAR5) compared to those with low sentiment.\n"
      ],
      "metadata": {
        "id": "tOIHjNhgOfKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation between Average Sentiment and 5-day abnormal return\n",
        "df_big[['vader_mean','CAR5']].corr()\n",
        "\n",
        "#Intepretation\n",
        "#The correlation between call sentiment and 5-day abnormal returns (0.0286) is very close to zero, indicating that managerial tone\n",
        "#has little to no short-term impact on market reaction. This suggests investors may have become desensitized to optimistic language,\n",
        "#focusing instead on tangible financial results.\n",
        "\n"
      ],
      "metadata": {
        "id": "9sBu_5OFAelt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How does CAR5 varies across sentiment quartiles or tertiles (Low/Mid/High)?\n",
        "df_big.groupby('sentiment_level')['CAR5'].agg(['mean','median','std','count'])\n",
        "\n",
        "#Intepratation\n",
        "#The mean and median CAR5 values both rise from low- to high-sentiment calls, indicating that more\n",
        "#positive management tone is generally associated with slightly better short-term stock performance. Additionally, the drop in standard\n",
        "#deviation suggests that optimistic calls lead to more stable and predictable market reactions, while negative tone triggers greater volatility.\n"
      ],
      "metadata": {
        "id": "QXU4BfWCPVWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplot\n",
        "sns.boxplot(\n",
        "    data=df_big,\n",
        "    x='sentiment_level',\n",
        "    y='CAR5',\n",
        "    hue='sentiment_level',\n",
        "    palette='mako',\n",
        "    legend=False\n",
        ")\n",
        "plt.title('5-Day CAR by Sentiment Level')\n",
        "plt.xlabel('Sentiment Level')\n",
        "plt.ylabel('5-Day Cumulative Abnormal Return (CAR5)')\n",
        "plt.show()\n",
        "\n",
        "#Intepretation\n",
        "#Firms with higher sentiment levels show slightly higher median 5-day abnormal returns,\n",
        "#but the wide overlap across groups suggests that tone alone has only a weak influence on short-term market reactions.\n"
      ],
      "metadata": {
        "id": "i_hS847dNpuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scatterplot with line of best fit\n",
        "sns.lmplot(data=df_big, x='vader_mean', y='CAR5', height=5, aspect=1.3,\n",
        "           scatter_kws={'alpha':0.6}, line_kws={'color':'red'})\n",
        "plt.title(\"Relationship between Call Sentiment and 5-Day Abnormal Return\")\n",
        "plt.xlabel(\"Average VADER Sentiment\")\n",
        "plt.ylabel(\"5-Day Cumulative Abnormal Return (CAR)\")\n",
        "\n",
        "#Intepretation\n",
        "#This scatterplot shows that there’s only a very weak positive relationship between\n",
        "#earnings call sentiment (VADER score) and 5-day abnormal returns (CAR5).\n",
        "#While the red trend line slopes slightly upward, it’s nearly flat, suggesting that more positive\n",
        "#tone does not strongly predict short-term market gains, though there may be a mild tendency for upbeat\n",
        "#calls to align with slightly higher returns."
      ],
      "metadata": {
        "id": "uYecJTSD9MWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Density Plot\n",
        "top = df_big[df_big['vader_mean'] > df_big['vader_mean'].quantile(0.9)]\n",
        "bottom = df_big[df_big['vader_mean'] < df_big['vader_mean'].quantile(0.1)]\n",
        "\n",
        "sns.kdeplot(top['CAR5'], fill=True, label='Top 10% Sentiment', color='green')\n",
        "sns.kdeplot(bottom['CAR5'], fill=True, label='Bottom 10% Sentiment', color='red')\n",
        "plt.title(\"Return Distribution: Most Positive vs. Most Negative Calls\")\n",
        "plt.xlabel(\"5-Day Cumulative Abnormal Return (CAR5)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "\n",
        "#Intepretation\n",
        "#On average, the market rewards strongly positive tone with slightly better short-term reactions.\n",
        "#Extremely negative tone, on the other hand, tends to precede worse performance.\n",
        "#Still, the broad overlap reveals that sentiment is only one of several factors driving post-earnings\n",
        "#stock behavior,it may act more as a signal amplifier than a determinant of returns.\n",
        "\n",
        "#The red (negative sentiment) distribution extends further into the left tail (negative CAR5 values), indicating\n",
        "#that the most pessimistic calls are more likely to be followed by larger short-term declines.\n",
        "#The green (positive) side tapers off earlier on the left, meaning fewer large losses occur after highly positive calls."
      ],
      "metadata": {
        "id": "zoB-KqL-9whd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Line Plot\n",
        "fig, axes = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
        "\n",
        "#Plot 1: Average Sentiment Tone\n",
        "sns.lineplot(data=df_big, x='fiscal_year', y='vader_mean', ax=axes[0], marker='o', color='steelblue')\n",
        "axes[0].set_title(\"Average Management Sentiment Over Time\", fontsize=12)\n",
        "axes[0].set_ylabel(\"Average VADER Sentiment Score\")\n",
        "\n",
        "#Plot 2: Average 5-Day Abnormal Return\n",
        "sns.lineplot(data=df_big, x='fiscal_year', y='CAR5', ax=axes[1], marker='o', color='darkorange')\n",
        "axes[1].set_title(\"Average 5-Day Cumulative Abnormal Return (CAR5) Over Time\", fontsize=12)\n",
        "axes[1].set_xlabel(\"Fiscal Year\")\n",
        "axes[1].set_ylabel(\"Average Cumulative Abnormal Return (CAR5)\")\n",
        "\n",
        "#Formatting\n",
        "fig.suptitle(\"Evolution of Sentiment and Market Reaction Across Fiscal Years\", fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Intepretation\n",
        "#Together, these trends suggest that while companies continue to use positive and confident language,\n",
        "#its predictive power for short-term stock reactions has weakened. In earlier years, optimistic tone\n",
        "#might have influenced investors, but more recently, markets appear less responsive to sentiment alone,\n",
        "#possibly due to greater access to data and automated analysis tools that reduce reliance on tone-based interpretation.\n"
      ],
      "metadata": {
        "id": "M94leN_H0HJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Findings from Research Question 1\n",
        "\n",
        "\n",
        "Firms that use more positive language in their earnings calls tend to show slightly higher short-term returns, particularly over the 3- and 5-day windows. However, the relationship is weak and not statistically strong, suggesting that while optimistic tone may boost market sentiment marginally, investors likely weigh fundamentals more heavily than tone alone."
      ],
      "metadata": {
        "id": "-UsYAFlx7Zbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Are certain sectors more sentiment-sensitive than others?"
      ],
      "metadata": {
        "id": "xDntOkUbOKZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Group means by sector\n",
        "df_big.groupby('chosen_sector')[['vader_mean', 'CAR5']].mean()\n",
        "\n",
        "#Interpretation\n",
        "#Technology and Consumer Discretionary firms show the highest positive CAR5 values,\n",
        "#suggesting stronger market reactions to earnings calls in these sectors. In contrast,\n",
        "#Communication Services and Financials have near-zero or negative CAR5, indicating weaker\n",
        "#or unfavorable investor responses. Health Care sits in the middle, with moderate sentiment and modest returns.\n"
      ],
      "metadata": {
        "id": "3HN2wFZGwlec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary Statistics for variability\n",
        "df_big.groupby(['chosen_sector', 'sentiment_level'])['CAR5'].std().unstack()\n",
        "\n",
        "#Interpretation\n",
        "#Volatility in 5-day abnormal returns (CAR5) varies notably across sectors.\n",
        "#Technology, Health Care, and Financials show decreasing volatility with more positive tone,\n",
        "#indicating steadier investor reactions to optimistic calls. In contrast, Communication Services\n",
        "#becomes more volatile under highly positive sentiment, suggesting divergent investor interpretations\n",
        "#of optimism. Consumer Discretionary remains volatile across all tones, reflecting consistent\n",
        "#sensitivity to management sentiment regardless of direction.\n"
      ],
      "metadata": {
        "id": "tSwQQkys1PHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation between sentiment and CAR5 by sector\n",
        "sector_corr = (\n",
        "    df_big.groupby('chosen_sector')[['vader_mean', 'CAR5']]\n",
        "    .corr()\n",
        "    .iloc[0::2, -1]\n",
        "    .reset_index(level=1, drop=True)  # drop the extra level\n",
        ")\n",
        "\n",
        "#Bar chart\n",
        "sector_corr.plot(kind='bar', color='teal')\n",
        "plt.title('Sentiment Sensitivity by Sector')\n",
        "plt.ylabel('Correlation between Sentiment & CAR')\n",
        "plt.xlabel('Sector')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Interpretation\n",
        "#Consumer Discretionary: Strongest positive correlation (~0.16).\n",
        "#Markets in this sector respond most to sentiment tone — upbeat calls tend to see higher post-earnings returns.\n",
        "\n",
        "#Health Care and Technology: Moderately positive correlations (~0.07–0.08).\n",
        "#Investor reactions align somewhat with sentiment, but less strongly.\n",
        "\n",
        "#Communication Services: Slight positive correlation (~0.03).\n",
        "#Weak link, tone matters a bit but not significantly.\n",
        "\n",
        "#Financials: Negative correlation (~–0.07).\n",
        "#Inverse pattern, optimistic tone doesn’t translate into higher abnormal returns, possibly\n",
        "#because financial investors focus more on quantitative indicators than tone.\n"
      ],
      "metadata": {
        "id": "emoIsVGE8GKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Which sectors see stronger reactions to earnings call tone?\n",
        "sector_returns = df_big.groupby('chosen_sector', observed=True)['CAR5'].mean().reset_index()\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.barplot(data=sector_returns, x='CAR5', y='chosen_sector', palette='viridis')\n",
        "plt.title('Average 5-Day CAR by Sector')\n",
        "plt.xlabel('Mean Cumulative Abnormal Return (CAR5)')\n",
        "plt.ylabel('Sector')\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#Investor reactions are most favorable in growth-oriented sectors like Technology and Consumer\n",
        "#Discretionary, while Communication Services lags, possibly due to weaker earnings momentum or lower sentiment credibility."
      ],
      "metadata": {
        "id": "miJyG8W9C4ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HeatMap\n",
        "pivot = df_big.pivot_table(values='CAR5', index='chosen_sector', columns='sentiment_level', aggfunc='mean')\n",
        "sns.heatmap(pivot, annot=True, cmap='YlGnBu')\n",
        "plt.title('Average 5-Day CAR by Sector and Sentiment Level')\n",
        "plt.xlabel('Sentiment Level')\n",
        "plt.ylabel('Sector')\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#Tone effects are sector-dependent: markets in Technology and Consumer Discretionary reward optimistic\n",
        "#language the most, while Financials and Health Care show modest reactions. Interestingly, Communication\n",
        "#Services shows an inverse pattern at high sentiment, hinting that overly positive tone might sometimes be\n",
        "#read as insincere or risky.\n"
      ],
      "metadata": {
        "id": "VsISDRvq3X06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do more positive tones in various sectors trigger higher trading activity?\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.scatterplot(data=df_big, x='vader_mean', y='volume_change', hue='chosen_sector', alpha=0.7)\n",
        "plt.title('Sentiment vs Change in Volume Around Earnings Calls')\n",
        "plt.xlabel('VADER Mean Sentiment')\n",
        "plt.ylabel('Volume Change (%)')\n",
        "plt.legend(bbox_to_anchor=(1.05,1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#The scatterplot reveals no strong relationship between management sentiment and trading\n",
        "#volume changes, suggesting that while positive tone may occasionally heighten investor attention,\n",
        "#sentiment primarily influences returns rather than trading activity levels."
      ],
      "metadata": {
        "id": "VRj6QcHsDv99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BoxPlot\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(data=df_big, x='shortName', y='vader_mean')\n",
        "plt.title('Sentiment (VADER Mean) Across Companies')\n",
        "plt.xlabel('Company Name')\n",
        "plt.ylabel('VADER Mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#Overall, sentiment levels vary meaningfully across firms, with large-cap tech and healthcare companies\n",
        "#(e.g., Google, Microsoft, J&J) maintaining the most consistently positive tone, while financial and\n",
        "#automotive firms (e.g., JPMorgan, Tesla) show greater volatility and mixed sentiment patterns — possibly\n",
        "#reflecting sector-specific uncertainty or cyclical exposure.\n"
      ],
      "metadata": {
        "id": "K_K5jMtrB7GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Findings from Research Question 2\n",
        "\n",
        "\n",
        "- Consumer Discretionary showed the strongest positive correlation (~0.16) between sentiment (VADER mean) and 5-day abnormal returns (CAR5). This suggests investors in this sector are highly responsive to optimistic communication, likely because consumer-facing businesses rely on confidence and demand expectations.\n",
        "\n",
        "- Technology and Health Care sectors displayed moderate positive sensitivity (~0.07–0.08), indicating that tone affects investor reaction, but other fundamentals still dominate.\n",
        "\n",
        "- Communication Services had only a weak positive link (~0.03), suggesting tone plays a minor role.\n",
        "\n",
        "- Financials exhibited a slight negative correlation (~–0.07), implying that overly positive tone may be viewed skeptically by investors who focus more on quantitative indicators like earnings and risk metrics.\n",
        "\n",
        "Overall Insight:\n",
        "Investor sentiment responses are sector-dependent, strongest where\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "narratives and consumer confidence drive value (e.g., discretionary and tech), and weakest where tangible data and fundamentals dominate (e.g., finance)."
      ],
      "metadata": {
        "id": "jtiFJDYC-Ady"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3. How do linguistic tone and communication style in earnings calls, reflected in word polarity, emotional intensity,\n",
        "#and sentence complexity influence short-term market reactions?"
      ],
      "metadata": {
        "id": "Kq-d2YWR9e1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive Statistics\n",
        "df_big[['vader_mean','positive_word_count','negative_word_count',\n",
        "        'uncertainty_word_count','avg_sentence_length',\n",
        "        'price_return_1day','price_return_5day','CAR5']].describe()\n",
        "\n",
        "#Interpretation\n",
        "#Earnings calls display a moderately positive tone (mean VADER = 0.26) with limited variation,\n",
        "#suggesting managers communicate optimistically but consistently. Positive words dominate (mean = 122)\n",
        "#compared to negative (23) and uncertain (39), indicating controlled use of negative or cautious language.\n",
        "#Sentences average 18.7 words, reflecting clear but structured communication. Market reactions are modestly\n",
        "#positive (mean CAR5 = 0.009), but the wide spread in returns implies that linguistic tone and style\n",
        "#influence investor responses unevenly across firms."
      ],
      "metadata": {
        "id": "cpkm0A_OXrg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How do sentiment scores vary across all transcripts?\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.histplot(df_big['vader_mean'], bins=30, kde=True, color='steelblue')\n",
        "plt.title('Distribution of Sentiment Across All Transcripts')\n",
        "plt.xlabel('VADER Mean Sentiment')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#The distribution is slightly right-skewed, centering around 0.25 to 0.30, which indicates\n",
        "#that most transcripts exhibit a mildly positive tone rather than neutrality or negativity.\n",
        "#There are very few observations below 0.15, suggesting that overtly negative sentiment is\n",
        "#rare in earnings calls—unsurprising, as management typically maintains optimistic or reassuring\n",
        "#language when communicating with investors.\n",
        "#The moderate variation between roughly 0.15 and 0.35 also shows that tone differences between\n",
        "#companies exist but are not extreme, meaning most firms use relatively similar levels of positivity."
      ],
      "metadata": {
        "id": "IPJm2ZSyCkp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cumulative Abnormal Return (CAR5) by Sentence Complexity\n",
        "\n",
        "df_big['complexity_group'] = pd.qcut(df_big['avg_sentence_length'], q=3, labels=['Simple','Moderate','Complex'])\n",
        "sns.violinplot(x='complexity_group', y='CAR5', data=df_big, inner='box', palette='mako')\n",
        "plt.title(\"CAR5 Distribution by Sentence Complexity\")\n",
        "plt.xlabel(\"Sentence Complexity\")\n",
        "plt.ylabel(\"5-Day Cumulative Abnormal Return (CAR5)\")\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#Calls with simpler language display slightly greater dispersion, suggesting that when managers\n",
        "#communicate more clearly, investor reactions are more volatile, possibly because messages are easier\n",
        "#to interpret, leading to stronger positive or negative responses."
      ],
      "metadata": {
        "id": "3mI1odvYXWgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Count vs. Cumulative Abnormal Return (CAR5)\n",
        "df_melt = df_big.melt(id_vars='CAR5',\n",
        "                      value_vars=['positive_word_count', 'negative_word_count', 'uncertainty_word_count'],\n",
        "                      var_name='Word_Type', value_name='Word_Count')\n",
        "\n",
        "sns.lmplot(x='Word_Count', y='CAR5', hue='Word_Type', data=df_melt,\n",
        "           scatter_kws={'alpha':0.4}, height=5, aspect=1.4)\n",
        "plt.title(\"Word Counts vs CAR5 by Type\")\n",
        "plt.xlabel(\"Word Count\")\n",
        "plt.ylabel(\"5-Day Abnormal Return (CAR5)\")\n",
        "plt.show()\n",
        "\n",
        "#Intepretation\n",
        "#Negative word count (orange) shows a slightly downward slope, suggesting that more frequent\n",
        "#use of negative words may correspond to marginally lower CAR5. This aligns with intuition,\n",
        "#pessimistic tone might dampen investor sentiment.\n",
        "\n",
        "#Positive word count (blue) has a very weak, near-flat positive slope, implying that upbeat\n",
        "#language does not necessarily generate stronger returns, at least in the short run.\n",
        "\n",
        "#Uncertainty word count (green) clusters tightly around zero, suggesting that uncertain language\n",
        "#is common but not clearly linked to abnormal returns — investors might already price in such ambiguity."
      ],
      "metadata": {
        "id": "jCkgW0l8SIbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Which linguistic features have the strongest relationship with returns?\n",
        "corr_cols = ['vader_mean','vader_pos_share','vader_neg_share','positive_word_count',\n",
        "             'negative_word_count','uncertainty_word_count','pos_neg_ratio',\n",
        "             'avg_sentence_length','price_return_1day',\n",
        "             'price_return_3day','price_return_5day','CAR5','volume_change']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(df_big[corr_cols].corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix: Text, Sentiment & Market Metrics')\n",
        "plt.show()\n",
        "\n",
        "#Interpretation\n",
        "#The correlation matrix reveals strong internal consistency among textual sentiment measures\n",
        "#but limited association with market outcomes. Positive and negative sentiment shares show\n",
        "#expected inverse relationships with overall VADER scores, while longer sentences are moderately\n",
        "#associated with more positive tone, suggesting that confident or optimistic management language\n",
        "#tends to be linguistically richer. Negative and uncertainty word counts are strongly related,\n",
        "#indicating that cautious communication often coincides with negative framing. However, the\n",
        "#negligible correlations between all sentiment metrics and post-earnings stock reactions\n",
        "#(CAR5 and short-term returns) imply that linguistic tone alone exerts little influence on short-term\n",
        "#market performance, with investors likely focusing on quantitative guidance rather than emotional tone."
      ],
      "metadata": {
        "id": "VhMn3biIDBa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Findings from Research Question 3\n",
        "\n",
        "\n",
        "The analysis of tone, emotional intensity, and sentence complexity reveals that management language influences market reactions only weakly and inconsistently, though certain linguistic patterns stand out:\n",
        "\n",
        "\n",
        "\n",
        "- Sentiment and Polarity: Earnings calls tend to be mildly positive overall (mean VADER ≈ 0.26), reflecting managers’ tendency to maintain optimism. The right-skewed sentiment distribution confirms that overtly negative tones are rare, as firms prefer confidence signaling during earnings disclosures.\n",
        "\n",
        "- Word Use and Market Impact: Negative word count shows a slight negative relationship with CAR5, suggesting that pessimistic or cautionary language modestly dampens investor response.\n",
        "\n",
        "- Positive word count has a nearly flat association, implying limited short-term reward for optimistic phrasing alone.\n",
        "\n",
        "- Uncertainty word use clusters around zero impact, indicating that ambiguity in language is expected and already priced in.\n",
        "\n",
        "- Sentence Complexity: The violin plot shows that calls with simpler sentences lead to wider variation in returns, when communication is clearer, investor interpretation and reaction are more direct and decisive. Complex language, on the other hand, correlates with more muted price movements, suggesting reduced clarity weakens market response.\n",
        "\n",
        "- Correlations and Feature Relationships:The heatmap confirms that textual sentiment measures (e.g., VADER scores, word counts, ratios) are internally consistent but show minimal correlation with short-term market performance. Longer sentences correlate slightly with more positive tone, implying that confidence may manifest through elaboration, but not necessarily in returns."
      ],
      "metadata": {
        "id": "b9ulc3b6CSIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key Findings (Summary)\n",
        "- Earnings calls are consistently, mildly positive (mean VADER ≈ 0.26); extreme tone is rare.  \n",
        "- Tone to returns: association is positive but modest on average; sentiment terciles show small differences in mean CAR5.  \n",
        "- By sector: Technology and Consumer Discretionary appear more tone‑sensitive; Financials least.  \n",
        "- Linguistic features: polarity balance and uncertainty terms align with small shifts in CAR5; emotional intensity relates more to dispersion/volume than average returns; sentence complexity has minimal effect on mean returns, though simpler language shows wider reaction spread.\n"
      ],
      "metadata": {
        "id": "CwijXt4k4B3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "This project examined how linguistic tone and communication style in corporate earnings calls shape short-term market reactions. Across all analyses, from sentiment distributions and word-count regressions to sector-wise correlations, the results indicate that language matters, but only marginally.\n",
        "\n",
        "While management consistently adopts a mildly optimistic tone, this positivity shows limited direct influence on abnormal returns (CAR5). Investors appear to discount excessive optimism and instead reward clarity, balance, and credibility. Simpler and more transparent communication correlates with more decisive market responses, while emotional or complex phrasing tends to blur investor interpretation.\n",
        "\n",
        "Sectoral analysis further highlights that sentiment sensitivity varies by industry, consumer-facing sectors like Consumer Discretionary and Technology respond more to tone, whereas Financials exhibit an inverse pattern, prioritizing quantitative indicators over verbal nuance.\n",
        "\n",
        "Ultimately, the findings suggest that effective financial communication lies not in emotional persuasion, but in linguistic precision. Tone can complement fundamentals but rarely substitutes for them, reinforcing that markets value clarity, transparency, and substance over rhetoric."
      ],
      "metadata": {
        "id": "XGSgEmm4-OUB"
      }
    }
  ]
}